{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservance Fish Identification Using CNN Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import iglob\n",
    "from models import Vgg16BN, Inception, Resnet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "split_train_path = data_path + '/train/'\n",
    "full_train_path = data_path + '/train_full/'\n",
    "valid_path = data_path + '/valid/'\n",
    "test_path = DATA_HOME_DIR + '/test/'\n",
    "saved_model_path = ROOT_DIR + '/models/'\n",
    "submission_path = ROOT_DIR + '/submissions/'\n",
    "\n",
    "# data\n",
    "batch_size = 16\n",
    "nb_split_train_samples = 3177\n",
    "nb_full_train_samples = 3777\n",
    "nb_valid_samples = 600\n",
    "nb_test_samples = 1000\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)\n",
    "\n",
    "# model\n",
    "nb_runs = 5\n",
    "nb_epoch = 10\n",
    "nb_aug = 7\n",
    "dropout = 0.0\n",
    "clip = 0.01\n",
    "use_val = False\n",
    "archs = [\"vggbn\"]\n",
    "\n",
    "models = {\n",
    "    \"vggbn\": Vgg16BN(size=(270, 480), n_classes=nb_classes, lr=0.001,\n",
    "                           batch_size=batch_size, dropout=dropout),\n",
    "    \"inception\": Inception(size=(299, 299), n_classes=nb_classes,\n",
    "                           lr=0.001, batch_size=batch_size),\n",
    "    \"resnet\": Resnet50(size=(270, 480), n_classes=nb_classes, lr=0.001,\n",
    "                    batch_size=batch_size, dropout=dropout)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a training loop that runs `nb_runs` times and trains a model for each architecture we've specified. \n",
    "\n",
    "We have the option to use validation data or the full training set -- if we use \n",
    "the former, the best model from each training loop will be saved and the path appended to our `models` list for \n",
    "later use; if the latter, we just save the weights from the last epoch of each training loop, since there's no validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(parent_model, model_str):\n",
    "    parent_model.build()    \n",
    "    model_fn = saved_model_path + '{val_loss:.2f}-loss_{epoch}epoch_' + model_str\n",
    "    ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    if use_val:\n",
    "        parent_model.fit_val(split_train_path, valid_path, nb_trn_samples=nb_split_train_samples, \n",
    "                             nb_val_samples=nb_valid_samples, nb_epoch=nb_epoch, callbacks=[ckpt], aug=nb_aug)\n",
    "\n",
    "        model_path = max(iglob(saved_model_path + '*.h5'), key=os.path.getctime)\n",
    "        return model_path\n",
    "    \n",
    "    model_fn = saved_model_path + '{}epoch_'.format(nb_epoch) + model_str\n",
    "    parent_model.fit_full(full_train_path, nb_trn_samples=nb_full_train_samples, nb_epoch=nb_epoch, aug=nb_aug)\n",
    "    model = parent_model.model\n",
    "    model.save_weights(model_fn)\n",
    "    del parent_model.model \n",
    "    \n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Run 1 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "228s - loss: 3.0301 - acc: 0.5933\n",
      "Epoch 2/10\n",
      "228s - loss: 1.0354 - acc: 0.7673\n",
      "Epoch 3/10\n",
      "228s - loss: 0.6544 - acc: 0.8425\n",
      "Epoch 4/10\n",
      "228s - loss: 0.4658 - acc: 0.8795\n",
      "Epoch 5/10\n",
      "228s - loss: 0.3584 - acc: 0.9081\n",
      "Epoch 6/10\n",
      "228s - loss: 0.2943 - acc: 0.9203\n",
      "Epoch 7/10\n",
      "228s - loss: 0.2748 - acc: 0.9275\n",
      "Epoch 8/10\n",
      "228s - loss: 0.2059 - acc: 0.9402\n",
      "Epoch 9/10\n",
      "228s - loss: 0.2112 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "228s - loss: 0.1444 - acc: 0.9603\n",
      "Starting Training Run 2 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "228s - loss: 3.5158 - acc: 0.5700\n",
      "Epoch 2/10\n",
      "229s - loss: 1.0049 - acc: 0.7665\n",
      "Epoch 3/10\n",
      "231s - loss: 0.6470 - acc: 0.8438\n",
      "Epoch 4/10\n",
      "230s - loss: 0.5127 - acc: 0.8732\n",
      "Epoch 5/10\n",
      "229s - loss: 0.3590 - acc: 0.9092\n",
      "Epoch 6/10\n",
      "228s - loss: 0.2989 - acc: 0.9216\n",
      "Epoch 7/10\n",
      "229s - loss: 0.2466 - acc: 0.9301\n",
      "Epoch 8/10\n",
      "229s - loss: 0.2126 - acc: 0.9425\n",
      "Epoch 9/10\n",
      "228s - loss: 0.1742 - acc: 0.9555\n",
      "Epoch 10/10\n",
      "228s - loss: 0.1512 - acc: 0.9563\n",
      "Starting Training Run 3 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n",
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "229s - loss: 3.0737 - acc: 0.5960\n",
      "Epoch 2/10\n",
      "229s - loss: 0.9602 - acc: 0.7755\n",
      "Epoch 3/10\n",
      "229s - loss: 0.6619 - acc: 0.8366\n",
      "Epoch 4/10\n",
      "229s - loss: 0.4529 - acc: 0.8809\n",
      "Epoch 5/10\n",
      "229s - loss: 0.3862 - acc: 0.9036\n",
      "Epoch 6/10\n",
      "228s - loss: 0.2850 - acc: 0.9227\n",
      "Epoch 7/10\n",
      "228s - loss: 0.2395 - acc: 0.9383\n",
      "Epoch 8/10\n",
      "228s - loss: 0.1868 - acc: 0.9526\n",
      "Epoch 9/10\n",
      "228s - loss: 0.2085 - acc: 0.9468\n",
      "Epoch 10/10\n",
      "228s - loss: 0.1544 - acc: 0.9547\n",
      "Starting Training Run 4 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n",
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "228s - loss: 3.1974 - acc: 0.5902\n",
      "Epoch 2/10\n",
      "228s - loss: 1.0066 - acc: 0.7683\n",
      "Epoch 3/10\n",
      "228s - loss: 0.6556 - acc: 0.8430\n",
      "Epoch 4/10\n",
      "228s - loss: 0.4335 - acc: 0.8848\n",
      "Epoch 5/10\n",
      "228s - loss: 0.3738 - acc: 0.9087\n",
      "Epoch 6/10\n",
      "228s - loss: 0.3113 - acc: 0.9203\n",
      "Epoch 7/10\n",
      "228s - loss: 0.2243 - acc: 0.9378\n",
      "Epoch 8/10\n",
      "228s - loss: 0.2203 - acc: 0.9436\n",
      "Epoch 9/10\n",
      "230s - loss: 0.1731 - acc: 0.9555\n",
      "Epoch 10/10\n",
      "229s - loss: 0.1638 - acc: 0.9537\n",
      "Starting Training Run 5 of 5...\n",
      "\n",
      "Training vggbn model...\n",
      "\n",
      "Found 3777 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "228s - loss: 3.0920 - acc: 0.5928\n",
      "Epoch 2/10\n",
      "228s - loss: 1.0111 - acc: 0.7739\n",
      "Epoch 3/10\n",
      "228s - loss: 0.6466 - acc: 0.8441\n",
      "Epoch 4/10\n",
      "228s - loss: 0.4406 - acc: 0.8782\n",
      "Epoch 5/10\n",
      "228s - loss: 0.3587 - acc: 0.9097\n",
      "Epoch 6/10\n",
      "228s - loss: 0.2953 - acc: 0.9179\n",
      "Epoch 7/10\n",
      "228s - loss: 0.2176 - acc: 0.9407\n",
      "Epoch 8/10\n",
      "228s - loss: 0.2651 - acc: 0.9341\n",
      "Epoch 9/10\n",
      "228s - loss: 0.1837 - acc: 0.9502\n",
      "Epoch 10/10\n",
      "228s - loss: 0.1473 - acc: 0.9592\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def train_all():    \n",
    "    model_paths = {\n",
    "        \"vggbn\": [],\n",
    "        \"inception\": [],\n",
    "        'resnet': [],\n",
    "    }\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"Starting Training Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        aug_str = \"aug\" if nb_aug else \"no-aug\"\n",
    "        \n",
    "        for arch in archs:\n",
    "            print(\"Training {} model...\\n\".format(arch))\n",
    "            model = models[arch]\n",
    "            model_str = \"{0}x{1}_{2}_{3}lr_run{4}_{5}.h5\".format(model.size[0], model.size[1], aug_str,\n",
    "                                                                 model.lr, run, arch)\n",
    "            model_path = train(model, model_str)\n",
    "            model_paths[arch].append(model_path)\n",
    "        \n",
    "    print(\"Done.\") \n",
    "    return model_paths\n",
    "        \n",
    "model_paths = train_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Prediction Run 1 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/robert/anaconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 2 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 3 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 4 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Starting Prediction Run 5 of 5...\n",
      "\n",
      "\n",
      "--Predicting on Augmentation 1 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 2 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 3 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 4 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 5 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 6 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "--Predicting on Augmentation 7 of 7...\n",
      "\n",
      "----Predicting on vggbn model...\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def test(model_paths):    \n",
    "    predictions_full = np.zeros((nb_test_samples, nb_classes))\n",
    "    \n",
    "    for run in range(nb_runs):\n",
    "        print(\"\\nStarting Prediction Run {0} of {1}...\\n\".format(run+1, nb_runs))\n",
    "        predictions_aug = np.zeros((nb_test_samples, nb_classes))\n",
    "        \n",
    "        for aug in range(nb_aug):\n",
    "            print(\"\\n--Predicting on Augmentation {0} of {1}...\\n\".format(aug+1, nb_aug))\n",
    "            predictions_mod = np.zeros((nb_test_samples, nb_classes))\n",
    "            \n",
    "            for arch in archs:\n",
    "                print(\"----Predicting on {} model...\".format(arch))\n",
    "                parent = models[arch]\n",
    "                model = parent.build()\n",
    "                model.load_weights(model_paths[arch][run])\n",
    "                pred, filenames = parent.test(test_path, nb_test_samples, aug=nb_aug)\n",
    "                predictions_mod += pred\n",
    "            \n",
    "            predictions_mod /= len(archs)\n",
    "            predictions_aug += predictions_mod\n",
    "\n",
    "        predictions_aug /= nb_aug\n",
    "        predictions_full += predictions_aug\n",
    "    \n",
    "    predictions_full /= nb_runs\n",
    "    return predictions_full, filenames\n",
    "\n",
    "predictions, filenames = test(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Predictions to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Predictions to CSV...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def write_submission(predictions, filenames):\n",
    "    preds = np.clip(predictions, clip, 1-clip)\n",
    "    sub_fn = submission_path + '{0}epoch_{1}aug_{2}clip_{3}runs'.format(nb_epoch, nb_aug, clip, nb_runs)\n",
    "    \n",
    "    for arch in archs:\n",
    "        sub_fn += \"_{}\".format(arch)\n",
    "\n",
    "    with open(sub_fn + '.csv', 'w') as f:\n",
    "        print(\"Writing Predictions to CSV...\")\n",
    "        f.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "        for i, image_name in enumerate(filenames):\n",
    "            pred = ['%.6f' % p for p in preds[i, :]]\n",
    "            f.write('%s,%s\\n' % (os.path.basename(image_name), ','.join(pred)))\n",
    "        print(\"Done.\")\n",
    "\n",
    "write_submission(predictions, filenames)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
