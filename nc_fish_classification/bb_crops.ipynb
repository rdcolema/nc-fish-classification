{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservancy Fish Classification - BB Crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ujson as json\n",
    "import PIL\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "full_train_path = data_path + 'train_full/'\n",
    "crop_path = data_path + 'cropped/'\n",
    "\n",
    "# data\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Images to Bounding Box Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, because a few fish have been relabeled in the training set, the classes won't line up exactly with the classes in the annotation files. \n",
    "\n",
    "As a roundabout way of getting around this, I create a dictionary mapping image files with their respective classes so that when I iterate through the annotation files I can pair them up on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Records: 3777\n"
     ]
    }
   ],
   "source": [
    "class_dict = defaultdict(str)\n",
    "\n",
    "for fp in glob(full_train_path + '*/*g'):\n",
    "    cls = fp.split('/')[-2]\n",
    "    im = fp.split('/')[-1]\n",
    "    class_dict[im] = cls\n",
    "    \n",
    "print(\"Image Records:\", len(class_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I iterate through each class, grab the annotations for that class, crop the image down to a square around the fish, and save it to my cropped data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB img_07008.jpg\n",
      "ALB img_06460.jpg\n",
      "ALB img_04798.jpg\n",
      "ALB img_02292.jpg\n",
      "ALB img_01958.jpg\n",
      "ALB img_00576.jpg\n",
      "ALB img_00568.jpg\n",
      "ALB img_00425.jpg\n",
      "BET img_00379.jpg\n",
      "DOL img_06773.jpg\n",
      "DOL img_05444.jpg\n",
      "SHARK ../data/train/SHARK/img_06082.jpg\n",
      "YFT ../data/train/YFT/img_04558.jpg\n",
      "YFT ../data/train/YFT/img_03183.jpg\n",
      "YFT ../data/train/YFT/img_02785.jpg\n"
     ]
    }
   ],
   "source": [
    "for c in classes:\n",
    "    \n",
    "#     if c == \"NoF\":  # no annotations for fish-less images, so we do a random crop\n",
    "#         fns = glob(full_train_path + c + '/*g')\n",
    "#         for fn in fns:\n",
    "#             im = PIL.Image.open(fn)\n",
    "            \n",
    "#             ht = random.uniform(96, 336)\n",
    "#             wt = random.uniform(96, 336)\n",
    "#             mx_dim = max([ht, wt])\n",
    "#             x = random.uniform(8, im.size[0]-336)\n",
    "#             y = random.uniform(8, im.size[1]-336)\n",
    "            \n",
    "#             cropped = im.crop((x, y, x + mx_dim, y + mx_dim))\n",
    "#             cropped.save(fn.replace(full_train_path, crop_path)) \n",
    "#         continue\n",
    "\n",
    "    \n",
    "    j = json.load(open('bb_annotations/{}.json'.format(c.lower()), 'r'))\n",
    "    \n",
    "    for l in j: \n",
    "        if 'annotations' in l.keys() and len(l['annotations']) > 0:\n",
    "            fn = l['filename'].split('/')[-1]\n",
    "            cls = class_dict[fn]\n",
    "            im = PIL.Image.open('{0}{1}/{2}'.format(full_train_path, cls, fn))\n",
    "            anno = sorted(l['annotations'], key=lambda x: x['height']*x['width'])[-1]\n",
    "            \n",
    "            mx_dim = max([anno['width'], anno['height']])           \n",
    "            x = anno['x']\n",
    "            y = anno['y']\n",
    "\n",
    "            cropped = im.crop((x, y, x + mx_dim, y + mx_dim))\n",
    "            cropped.save('{0}{1}/{2}'.format(crop_path, cls, fn))\n",
    "        else:\n",
    "            print(c, l['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped Image Records: 3297\n"
     ]
    }
   ],
   "source": [
    "crops = glob(crop_path + '*/*g')\n",
    "\n",
    "print(\"Cropped Image Records:\", len(crops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a few records were lost in the process (in addition to the ones printed out above), but after looking through some of the missing annotations, there's generally a good reason, such as multiple fish or obscured fish. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
